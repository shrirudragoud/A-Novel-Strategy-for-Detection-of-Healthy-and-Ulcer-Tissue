# A Novel Strategy for Detection of Healthy and Ulcer Tissue from Endoscopic Images

## Abstract

This research presents an end-to-end, practical medical imaging pipeline designed to detect healthy versus ulcer tissue from gastrointestinal (GI) endoscopy images. The proposed approach leverages a hybrid methodology combining deep learning-based feature extraction with classical, well-regularized machine learning. RGB endoscopy images are first transformed into compact, high-level embeddings using a pretrained **EfficientNetB0** model trained on ImageNet. These embeddings are then subjected to supervised dimensionality reduction via **Partial Least Squares (PLS)**, which extracts components maximally predictive of tissue categories. The reduced representation is classified using a **Radial Basis Function Support Vector Machine (RBF-SVM)**, chosen for its strong generalization capability and ability to model nonlinear decision boundaries.

To address severe class imbalance between healthy, ulcer, and polyp images, the study integrates **class weighting**, **controlled oversampling**, and **post-hoc probability reweighting** techniques, all optimized through validation experiments. The proposed framework achieves state-of-the-art performance with reproducible training commands, clear interpretability, and robust telemetry for clinical deployment.

---

## Methodology

This applied research employs quantitative modeling, integrating both linear and nonlinear components to achieve precise tissue classification. Initially, **Partial Least Squares (PLS)** modeling is conducted on the original dual-position dataset (DS) to capture primary correlations between features and tissue labels. The PLS model, however, yields low and underfitting training results, confirming the nonlinear scattering effects present in endoscopic data.

To overcome these limitations, a **nonlinear Radial Basis Function Neural Network (RBF-NN)** is subsequently employed using the combined dataset (**TV-EMD dual-position DS**). The RBF-NN effectively models complex nonlinear relationships, demonstrating significant improvements in classifying ulcer and polyp tissues while reducing noise and preserving key spatial patterns.

The combined **PLS–RBF-NN** modeling framework offers both interpretability and high predictive accuracy, validating the nonlinear nature of the scattering phenomena and its impact on ulcer detection performance.

---

## Keywords

**Ulcer Detection**, **Endoscopy**, **Partial Least Squares**, **RBF Neural Network**, **EfficientNetB0**, **Medical Imaging**, **Nonlinear Modeling**, **Noise Reduction**


## Visual Summary

Healthy and lesion-focused occlusion sensitivity maps (left: original|overlay composite, right: overlay only). Examples below are generated by `tools/explain_occlusion.py`.

### Explainability Visualizations

| Healthy Tissue | Ulcer Lesion | Polyp Lesion |
|:--------------:|:------------:|:------------:|
| ![Healthy example](artifacts/explain/occlusion_composite_5e59c7fdb16c4228_7938_healthy.png) |![Ulcer example](artifacts/explain/occlusion_composite_d626f4f4a5ac4785_48402_ulcer.png) | ![Polyp example](artifacts/explain/occlusion_composite_131368cc17e44240_28976_polyp.png) |

### Evaluation Metrics (Best Run: `cnn_fast_cw`)

| Tsne_test_balanced (Test) | ROC Curves (Test) |
|:----------------------:|:-----------------:|
| ![Tsne_test Matrix](artifacts/cnn_fast_cw_(Best_Model)/tsne_test_balanced.png) | ![Confusion_test](artifacts/cnn_fast_cw/confusion_test.png) |
## Results (Best Run: cnn_fast_cw)

### Performance Metrics
- **Validation**: Accuracy **0.9991**, Macro-F1 **0.9939**
- **Test**: Accuracy **0.9983**, Macro-F1 **0.9882**

### Model Configuration
- **Best hyperparameters**:
  - PLS components: `24`
  - SVM C: `4`
  - SVM gamma: `scale`
  - Class weight: `balanced`
- **Oversampling strategy**: `[healthy, ulcer, polyp] = [1×, 6×, 40×]` duplication on train only

### Artifacts Location
All model artifacts are saved under:
```
artifacts/cnn_fast_cw/
├── scaler.pkl
├── pls.pkl
├── svm.pkl
├── metrics.json
├── confusion_val.png
├── confusion_test.png
├── roc_val.png
└── roc_test.png
```

## Methodology

### 1. Data Organization
- Images stored in: `dataset/images/{healthy,ulcer,polyp}/`
- Split lists: `dataset/splits/{train,val,test}.txt`
- Label mappings: `dataset/metadata/{class_map.json,labels.csv}`

### 2. Feature Extraction (CNN)
- **Backbone**: EfficientNetB0 (torchvision, pretrained on ImageNet)
- **Output dimension**: 1280-D embeddings per image
- **Saved format**: `dataset/features_cnn/{split}_X.npy`, `{split}_y.npy`, `{split}_paths.txt`

### 3. Dimensionality Reduction
- **Method**: Supervised Partial Least Squares (PLS)
- **Implementation**: Custom `PLSTransformer` wrapper that one-hot encodes labels internally
- **Output**: Reduced feature space (typically 16-32 components) maximally correlated with class labels

### 4. Classification
- **Algorithm**: Support Vector Machine (SVM) with RBF kernel
- **Probability estimation**: Enabled for ROC/PR curve generation
- **Hyperparameter tuning**: Grid search with stratified cross-validation

### 5. Class Imbalance Handling
- **Class weighting**: `balanced` mode in SVM
- **Oversampling**: Controlled duplication of minority classes in training set
- **Post-hoc reweighting**: Probability adjustment based on validation performance

## Repository Structure

### Core Modules
- `src/deep/cnn_embedder.py`: EfficientNetB0 embedder with official transforms
- `src/models/pls_transformer.py`: Supervised PLS transformer returning X scores only
- `src/data/loader.py`: Dataset loading utilities
- `src/preprocess/image_ops.py`: Image preprocessing (color space conversion, denoising)

### Tools & Scripts
- `tools/extract_cnn_embeddings.py`: Extract and save CNN embeddings
- `tools/train_pls_svm.py`: Complete training pipeline with grid search, metrics, and visualization
- `tools/analyze_predictions.py`: Generate reports, misclassification CSV, and t-SNE visualizations
- `tools/infer_images.py`: Run inference on new images (CSV output)
- `tools/explain_occlusion.py`: Generate occlusion sensitivity maps (overlay + composite)
- `tools/build_explain_gallery.py`: Build HTML gallery for explainability outputs

### Optional (Classical Features)
- `src/features/emd_features.py`: Empirical Mode Decomposition feature extraction
- `tools/extract_features.py`: Extract IMF-based statistical features

## Quick Start

### Prerequisites
```bash
pip install -r requirements.txt
cd A-Novel-Strategy-for-Detection-of-Healthy-and-Ulcer-Tissue
export PYTHONPATH=$(pwd)
```

**Note**: Dataset images are not included in the repository. Download them separately (see setup instructions) or use your own dataset organized as `dataset/images/{healthy,ulcer,polyp}/`.

### Step 1: Extract CNN Embeddings
```bash
python tools/extract_cnn_embeddings.py \
  --dataset_root dataset \
  --out_root dataset/features_cnn \
  --splits train val test --batch_size 64 --device auto
```

### Step 2: Train Model (Best Configuration)
```bash
python tools/train_pls_svm.py \
  --features_root dataset/features_cnn \
  --artifacts_dir artifacts \
  --run_name cnn_fast_cw \
  --preset fast \
  --oversample_multipliers 1,6,40 \
  --proba_reweight_grid "1,1,1;1,3,10;1,4,15"
```

### Step 3: Analyze Results
```bash
# Generate comprehensive report + t-SNE visualization
python tools/analyze_predictions.py \
  --features_root dataset/features_cnn \
  --artifacts_dir artifacts/cnn_fast_cw \
  --split test --tsne
```

### Step 4: Explainability Analysis
```bash
# Generate occlusion maps for specific images
python tools/explain_occlusion.py \
  --artifacts_dir artifacts/cnn_fast_cw \
  --class_map dataset/metadata/class_map.json \
  --images dataset/images/ulcer/2fc3db471f9d44c0_1724.jpg \
  --patch 16 --stride 8 --device auto \
  --out_dir artifacts/explain

# Build HTML gallery
python tools/build_explain_gallery.py --explain_dir artifacts/explain
```

### Step 5: Inference on New Images
```bash
python tools/infer_images.py \
  --artifacts_dir artifacts/cnn_fast_cw \
  --images /path/to/image1.jpg /path/to/image2.png \
  --device auto \
  --out_csv artifacts/infer_results.csv
```

## Binary Variant (Healthy vs Ulcer Only)

For focused ulcer detection, you can create a balanced binary dataset. Commands available in `docs/COMMANDS_REFERENCE.md`.

## Explainability

### Occlusion Sensitivity Maps
- Visualize which image regions contribute most to predictions
- Generates both overlay and side-by-side composite images
- Fine-grained control via `--patch` and `--stride` parameters
- Index CSV maps images to their explainability outputs

### Analysis Tools
- Misclassification analysis with probabilities
- t-SNE visualization of feature space separability
- Classification reports with per-class metrics

## Documentation

Comprehensive documentation available in `docs/`:
- `CODEBASE_OVERVIEW.md`: High-level architecture and data flow
- `PIPELINE_AND_MODULES.md`: Detailed module explanations
- `COMMANDS_REFERENCE.md`: Complete command reference
- `BEST_RUN_CNN_FAST_CW.md`: Best run configuration and results
- `INFERENCE_AND_ANALYSIS.md`: Inference and analysis workflows

## Citation

If you use this work, please cite:

```bibtex
@software{endoscopy_classifier,
  title={A Novel Strategy for Detection of Healthy and Ulcer Tissue},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/endoscopy-classifier}
}
```

## License

Pretrained CNN weights provided by torchvision (EfficientNetB0). Ensure proper dataset licensing and attribution for medical images.

## Acknowledgments

- EfficientNetB0 pretrained weights via PyTorch/torchvision
- Scikit-learn for classical ML components
- PyEMD/EMD-signal for empirical mode decomposition (optional classical features)

