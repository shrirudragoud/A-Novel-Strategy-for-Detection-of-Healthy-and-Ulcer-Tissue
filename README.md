# A Novel Strategy for Detection of Healthy and Ulcer Tissue

End-to-end repository for a practical medical imaging pipeline that detects healthy vs. ulcer tissue from endoscopy images using a hybrid approach: pretrained CNN embeddings with a classical, well-regularized classifier (PLS + SVM). The repo also includes a classical IMF feature variant, rich telemetry, explainability tools, and reproducible commands.

## Abstract

We propose a simple yet strong pipeline for GI endoscopy classification. RGB images are converted into compact embeddings using EfficientNetB0 pretrained on ImageNet. A supervised dimensionality reduction (Partial Least Squares) extracts components maximally predictive of labels, followed by an RBF-SVM classifier. To handle severe class imbalance, we combine class weighting, controlled oversampling, and post-hoc probability reweighting (chosen on validation). This delivers state-of-the-art results on our dataset with clear, reproducible steps, plots, and interpretability.

## Visual Summary

Healthy and lesion-focused occlusion sensitivity maps (left: original|overlay composite, right: overlay only). Examples below are generated by `tools/explain_occlusion.py`.

### Explainability Visualizations

| Healthy Tissue | Ulcer Lesion | Polyp Lesion |
|:--------------:|:------------:|:------------:|
| ![Healthy example](artifacts/explain/occlusion_composite_5e59c7fdb16c4228_7938_healthy.png) |![Ulcer example](artifacts/explain/occlusion_composite_d626f4f4a5ac4785_48402_ulcer.png) | ![Polyp example](artifacts/explain/occlusion_composite_131368cc17e44240_28976_polyp.png) |

### Evaluation Metrics (Best Run: `cnn_fast_cw`)

| Tsne_test_balanced (Test) | ROC Curves (Test) |
|:----------------------:|:-----------------:|
| ![Tsne_test Matrix](artifacts/cnn_fast_cw_(Best_Model)/tsne_test_balanced.png) | ![Confusion_test](artifacts/cnn_fast_cw/confusion_test.png) |
## Results (Best Run: cnn_fast_cw)

### Performance Metrics
- **Validation**: Accuracy **0.9991**, Macro-F1 **0.9939**
- **Test**: Accuracy **0.9983**, Macro-F1 **0.9882**

### Model Configuration
- **Best hyperparameters**:
  - PLS components: `24`
  - SVM C: `4`
  - SVM gamma: `scale`
  - Class weight: `balanced`
- **Oversampling strategy**: `[healthy, ulcer, polyp] = [1×, 6×, 40×]` duplication on train only

### Artifacts Location
All model artifacts are saved under:
```
artifacts/cnn_fast_cw/
├── scaler.pkl
├── pls.pkl
├── svm.pkl
├── metrics.json
├── confusion_val.png
├── confusion_test.png
├── roc_val.png
└── roc_test.png
```

## Methodology

### 1. Data Organization
- Images stored in: `dataset/images/{healthy,ulcer,polyp}/`
- Split lists: `dataset/splits/{train,val,test}.txt`
- Label mappings: `dataset/metadata/{class_map.json,labels.csv}`

### 2. Feature Extraction (CNN)
- **Backbone**: EfficientNetB0 (torchvision, pretrained on ImageNet)
- **Output dimension**: 1280-D embeddings per image
- **Saved format**: `dataset/features_cnn/{split}_X.npy`, `{split}_y.npy`, `{split}_paths.txt`

### 3. Dimensionality Reduction
- **Method**: Supervised Partial Least Squares (PLS)
- **Implementation**: Custom `PLSTransformer` wrapper that one-hot encodes labels internally
- **Output**: Reduced feature space (typically 16-32 components) maximally correlated with class labels

### 4. Classification
- **Algorithm**: Support Vector Machine (SVM) with RBF kernel
- **Probability estimation**: Enabled for ROC/PR curve generation
- **Hyperparameter tuning**: Grid search with stratified cross-validation

### 5. Class Imbalance Handling
- **Class weighting**: `balanced` mode in SVM
- **Oversampling**: Controlled duplication of minority classes in training set
- **Post-hoc reweighting**: Probability adjustment based on validation performance

## Repository Structure

### Core Modules
- `src/deep/cnn_embedder.py`: EfficientNetB0 embedder with official transforms
- `src/models/pls_transformer.py`: Supervised PLS transformer returning X scores only
- `src/data/loader.py`: Dataset loading utilities
- `src/preprocess/image_ops.py`: Image preprocessing (color space conversion, denoising)

### Tools & Scripts
- `tools/extract_cnn_embeddings.py`: Extract and save CNN embeddings
- `tools/train_pls_svm.py`: Complete training pipeline with grid search, metrics, and visualization
- `tools/analyze_predictions.py`: Generate reports, misclassification CSV, and t-SNE visualizations
- `tools/infer_images.py`: Run inference on new images (CSV output)
- `tools/explain_occlusion.py`: Generate occlusion sensitivity maps (overlay + composite)
- `tools/build_explain_gallery.py`: Build HTML gallery for explainability outputs

### Optional (Classical Features)
- `src/features/emd_features.py`: Empirical Mode Decomposition feature extraction
- `tools/extract_features.py`: Extract IMF-based statistical features

## Quick Start

### Prerequisites
```bash
pip install -r requirements.txt
cd A-Novel-Strategy-for-Detection-of-Healthy-and-Ulcer-Tissue
export PYTHONPATH=$(pwd)
```

**Note**: Dataset images are not included in the repository. Download them separately (see setup instructions) or use your own dataset organized as `dataset/images/{healthy,ulcer,polyp}/`.

### Step 1: Extract CNN Embeddings
```bash
python tools/extract_cnn_embeddings.py \
  --dataset_root dataset \
  --out_root dataset/features_cnn \
  --splits train val test --batch_size 64 --device auto
```

### Step 2: Train Model (Best Configuration)
```bash
python tools/train_pls_svm.py \
  --features_root dataset/features_cnn \
  --artifacts_dir artifacts \
  --run_name cnn_fast_cw \
  --preset fast \
  --oversample_multipliers 1,6,40 \
  --proba_reweight_grid "1,1,1;1,3,10;1,4,15"
```

### Step 3: Analyze Results
```bash
# Generate comprehensive report + t-SNE visualization
python tools/analyze_predictions.py \
  --features_root dataset/features_cnn \
  --artifacts_dir artifacts/cnn_fast_cw \
  --split test --tsne
```

### Step 4: Explainability Analysis
```bash
# Generate occlusion maps for specific images
python tools/explain_occlusion.py \
  --artifacts_dir artifacts/cnn_fast_cw \
  --class_map dataset/metadata/class_map.json \
  --images dataset/images/ulcer/2fc3db471f9d44c0_1724.jpg \
  --patch 16 --stride 8 --device auto \
  --out_dir artifacts/explain

# Build HTML gallery
python tools/build_explain_gallery.py --explain_dir artifacts/explain
```

### Step 5: Inference on New Images
```bash
python tools/infer_images.py \
  --artifacts_dir artifacts/cnn_fast_cw \
  --images /path/to/image1.jpg /path/to/image2.png \
  --device auto \
  --out_csv artifacts/infer_results.csv
```

## Binary Variant (Healthy vs Ulcer Only)

For focused ulcer detection, you can create a balanced binary dataset. Commands available in `docs/COMMANDS_REFERENCE.md`.

## Explainability

### Occlusion Sensitivity Maps
- Visualize which image regions contribute most to predictions
- Generates both overlay and side-by-side composite images
- Fine-grained control via `--patch` and `--stride` parameters
- Index CSV maps images to their explainability outputs

### Analysis Tools
- Misclassification analysis with probabilities
- t-SNE visualization of feature space separability
- Classification reports with per-class metrics

## Documentation

Comprehensive documentation available in `docs/`:
- `CODEBASE_OVERVIEW.md`: High-level architecture and data flow
- `PIPELINE_AND_MODULES.md`: Detailed module explanations
- `COMMANDS_REFERENCE.md`: Complete command reference
- `BEST_RUN_CNN_FAST_CW.md`: Best run configuration and results
- `INFERENCE_AND_ANALYSIS.md`: Inference and analysis workflows

## Citation

If you use this work, please cite:

```bibtex
@software{endoscopy_classifier,
  title={A Novel Strategy for Detection of Healthy and Ulcer Tissue},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/endoscopy-classifier}
}
```

## License

Pretrained CNN weights provided by torchvision (EfficientNetB0). Ensure proper dataset licensing and attribution for medical images.

## Acknowledgments

- EfficientNetB0 pretrained weights via PyTorch/torchvision
- Scikit-learn for classical ML components
- PyEMD/EMD-signal for empirical mode decomposition (optional classical features)

